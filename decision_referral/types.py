import dataclasses
import enum
import os
from dataclasses import dataclass
from typing import Callable, Iterable, List, NamedTuple, Optional

import numpy as np
import pandas as pd
import pickle

from decision_referral import io_util, reweighing


@enum.unique
class Dataset(enum.Enum):
    INTERNAL_VALIDATION_SET = enum.auto()
    INTERNAL_TEST_SET = enum.auto()
    EXTERNAL_TEST_SET = enum.auto()


class DecisionReferralInputs:
    def __init__(self, df: pd.DataFrame):
        self.study_ids: np.ndarray = df.study_ids.values
        self.y_true: np.ndarray = df.y_true.values  # cancer yes/no

        # Normal triaging and safety net model scores
        self.y_score_nt: np.ndarray = df.y_score_nt.values
        self.y_score_sn: np.ndarray = df.y_score_sn.values

        # Radiologist > BI-RADS 2
        self.y_read_1: np.ndarray = df.y_read_1.values
        self.y_read_2: np.ndarray = df.y_read_2.values

        self.weights: np.ndarray = reweighing.calculate_representative_weights(
            {k: df[k].values for k in reweighing.REQUIRED_LABELS}
        )[0]

    @classmethod
    def from_disk(cls, dataset: Dataset):
        filename = os.path.join(io_util.INPUT_DIR, dataset.name.lower() + ".h5")
        return cls(pd.read_hdf(filename, key="table"))


@dataclass(frozen=True)
class ValueWithCI:
    value: float
    # None if CI can't be computed
    ci_low: Optional[float]
    ci_upp: Optional[float]

    def to_dict(self):
        return dataclasses.asdict(self)


class OperatingPoint(NamedTuple):
    name: str
    sensitivity: ValueWithCI
    specificity: ValueWithCI
    ppv: ValueWithCI

class HumanDelta(NamedTuple):
    is_super_human: bool
    sensitivity: float
    specificity: float
    ppv: float
    sensitivity_p_value: Optional[float] = None
    specificity_p_value: Optional[float] = None

    def to_dict(self):
        return self._asdict()

    def __repr__(self) -> str:
        # only used when loading DRRs that were saved with the old __repr__
        if None in {self.is_super_human, self.sensitivity, self.specificity}:
            return "None"
        return (
            f"{type(self).__name__}(is_super_human={self.is_super_human}, "
            f"delta_sensitivity={self.sensitivity:.2%}, delta_specificity={self.specificity:.2%})"
        )


class ResultsTuple(NamedTuple):
    name: str
    sensitivity: ValueWithCI
    specificity: ValueWithCI
    ppv: ValueWithCI
    delta: Optional[HumanDelta]
    selection_confident: Optional[np.ndarray]  # indicates where model predictions are confident
    rule_out: Optional[float] = None
    min_sensitivity: Optional[float] = None
    min_specificity: Optional[float] = None
    lower_threshold: Optional[float] = None
    upper_threshold: Optional[float] = None

    def is_better_than(self, other: "ResultsTuple") -> bool:
        return (
            self.sensitivity.value > other.sensitivity.value
            and self.specificity.value > other.specificity.value
            and self.ppv.value > other.ppv.value
        )

    @property
    def selection_unconfident(self):
        return ~self.selection_confident

    def to_dict(self):
        return {k: v.to_dict() if "to_dict" in dir(v) else v for k, v in self._asdict().items()}


class DecisionReferralResult(List[ResultsTuple]):

    FILENAME = "decision_referral_result.pkl"

    def to_data_frame(self) -> pd.DataFrame():
        # Flatten each ResultsTuple into one row in a table
        df_results = pd.json_normalize([rt.to_dict() for rt in self], sep="_")
        # Unify missing values (some are np.nan as a result of computations, some aren't set, i.e. None)
        df_results = df_results.fillna(value=np.nan)
        # Autogenerated column names from flattening ResultsTuple are mostly fine; adjustments go here:
        df_results = df_results.rename(columns={"delta_is_super_human": "is_super_human"})

        df_results = df_results.set_index("name")
        return df_results

    def to_csv(self, output_dir: str, format_func: Optional[Callable[[pd.DataFrame], pd.DataFrame]]):
        """Save DRR as a (formatted) CSV for regulatory, publication, etc."""
        df = self.to_data_frame()
        if format_func is not None:
            df = format_func(df)
        df.to_csv(os.path.join(output_dir, "results_table.csv"))

    def get_result_tuple_by_name(self, name: str) -> ResultsTuple:
        return next(result_tuple for result_tuple in self if result_tuple.name == name)

    def get_result_tuple(self, min_sensitivity: Optional[float], min_specificity: Optional[float]) -> ResultsTuple:
        return next(
            result_tuple
            for result_tuple in self
            if result_tuple.min_sensitivity == min_sensitivity and result_tuple.min_specificity == min_specificity
        )

    def filter(self, filter_set: Iterable[str]) -> "DecisionReferralResult":
        """Filters DRR leaving a subset of operating points."""
        return DecisionReferralResult([result_tuple for result_tuple in self if result_tuple.name in filter_set])

    @classmethod
    def load(cls, output_dir: str) -> "DecisionReferralResult":
        """Load class instance from pickle file"""
        return io_util.load_from_pickle(os.path.join(output_dir, cls.FILENAME))

    def save(self, output_dir: str):
        """Dump class instance to pickle file"""
        io_util.save_to_pickle(self, os.path.join(output_dir, self.FILENAME), protocol=pickle.HIGHEST_PROTOCOL)
